import numpy as np
import pandas as pd
from tensorflow.keras import models, layers
from tensorflow.keras.callbacks import EarlyStopping
import matplotlib.pyplot as plt

a = pd.read_csv('/home/oms315/Desktop/HW2.txt')

a.columns = ['id', 'Clump Thickness', 'Uniformity of Cell Size', 'Uniformity of Cell Shape',
             'Marginal Adhesion', 'Single Epithelial Cell Size', 'Bare Nuclei', 'Bland Chromatin',
             'Normal Nucleoli', 'Mitoses', 'Class']

a.drop(['id'], inplace=True, axis=1)
a['Class'] = a['Class'].map(lambda k: 1 if k == 4 else 0)

x = np.array(a.drop(['Class'], axis=1))
y = np.array(a['Class'])

test_data = x[:100].astype('float64')
test_targets = y[:100].astype('float64')
val_data = x[100:200].astype('float64')
val_targets = y[100:200].astype('float64')
train_data = x[200:].astype('float64')
train_targets = y[200:].astype('float64')

mean = train_data.mean(axis=0)
train_data -= mean
std = train_data.std(axis=0)
train_data /= std
test_data -= mean
test_data /= std
val_data -= mean
val_data /= std


model = models.Sequential()
model.add(layers.Dense(10, activation='relu', input_shape=(9,)))
model.add(layers.Dense(10, activation='relu'))
model.add(layers.Dense(1, activation='sigmoid'))

model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])

history = model.fit(train_data, train_targets, epochs=200, batch_size=10, validation_data=(val_data, val_targets),
                    callbacks=[EarlyStopping(monitor='val_loss', patience=2)])

result = model.evaluate(test_data, test_targets)

print(result)
print(model.predict(test_data))
print(test_targets)


def plot_loss(h, title="loss"):
    plt.plot(h.history['loss'])
    plt.plot(h.history['val_loss'])
    plt.title(title)
    plt.ylabel('Loss')
    plt.xlabel('Epoch')
    plt.legend(['Training', 'Validation'], loc=0)
    plt.show()


plot_loss(history)
